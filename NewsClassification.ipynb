{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728e65df-6141-4c94-ad01-62ac16c42677",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8646ccb-eb15-4304-a852-ce66366e88df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Extract each type of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1b4fd8-1bec-47fd-8131-8330d730a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.common.keys import Keys \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebaadb9a-5fb7-4921-bb4a-fc367aef8751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Business \n",
      "\n",
      "\n",
      " Technology \n",
      "\n",
      "\n",
      " Entertainment \n",
      "\n",
      "\n",
      " Sports \n",
      "\n",
      "\n",
      " Science \n",
      "\n",
      "\n",
      " Health \n",
      "\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://news.google.com/home?hl=en-IN&gl=IN&ceid=IN:en\")\n",
    "buttons =  driver.find_elements(By.CLASS_NAME,\"EctEBd\")\n",
    "\n",
    "heading = \"\"\n",
    "data = []\n",
    "\n",
    "for button in buttons:\n",
    "    data_n_ini = button.get_attribute(\"data-n-ini\")\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        if data_n_ini.isdigit() and  8 <= int(data_n_ini) and 13 >= int(data_n_ini) : \n",
    "            a = button.find_element(By.TAG_NAME, 'a')\n",
    "            a.click()\n",
    "            print(\"\\n\",a.text)\n",
    "            heading = a.text\n",
    "            time.sleep(5)\n",
    "            #\n",
    "            labels = driver.find_elements(By.CLASS_NAME,\"gPFEn\")\n",
    "            \n",
    "            for lab in labels:\n",
    "                if lab.text != \"\":\n",
    "                    # print(lab.text,\"\\n\")\n",
    "                    data.append({'label':heading,'content':lab.text})\n",
    "            \n",
    "    \n",
    "    except ValueError:\n",
    "        continue\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11248ae5-891c-4709-a7d5-83a8ee69deb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Business',\n",
       " 'content': 'Union Budget 2025: Electric vehicles to become affordable'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29001d-f4c1-4663-81e8-1ab174cd2920",
   "metadata": {},
   "source": [
    "### Write data into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f47653e6-45be-42a7-854c-a6dd08d78cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "897e4578-ee08-44a3-9730-c6fc5542aa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"newsdataset.csv\"\n",
    "\n",
    "with open(csv_file, mode = \"w\" , newline=\"\", encoding = \"utf-8\") as file:\n",
    "    filenames = ['label','content']\n",
    "\n",
    "    writer = csv.DictWriter(file,fieldnames = filenames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    writer.writerows(data)\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1f89c-0731-4a6d-b968-504670ce2558",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66a783de-efe3-42d4-8bad-092d948f7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8066e5da-7b63-4fcc-8caf-4d9f1861e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16e04346-c59b-4361-ae2a-4cfc7ae8a605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>Maruti Suzuki's vehicle dispatches from factor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business</td>\n",
       "      <td>Non-tax revenue from telecom pegged 33 pc lowe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Health</td>\n",
       "      <td>AI model predicts dengue outbreaks two months ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health</td>\n",
       "      <td>Handful of California Almonds a Day: Natural A...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Sankranthiki Vasthunnam team plans a grand fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                            content  \\\n",
       "0       Business  Maruti Suzuki's vehicle dispatches from factor...   \n",
       "1       Business  Non-tax revenue from telecom pegged 33 pc lowe...   \n",
       "2         Health  AI model predicts dengue outbreaks two months ...   \n",
       "3         Health  Handful of California Almonds a Day: Natural A...   \n",
       "4  Entertainment  Sankranthiki Vasthunnam team plans a grand fin...   \n",
       "\n",
       "   label_encoded  \n",
       "0              0  \n",
       "1              0  \n",
       "2              2  \n",
       "3              2  \n",
       "4              1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('newsdataset.csv')\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1dbe4e4-1e8e-4f71-8a60-089edf2c2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e3272-93d7-4683-9410-c5ba26e23865",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 100,oov_token=\"<OOV>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2743c9-cb32-4d31-9ecf-6972e4c55155",
   "metadata": {},
   "outputs": [],
   "source": [
    "To create a model that classifies the type of news based on the content, using the label and content of news articles, we'll follow these general steps:\n",
    "\n",
    "1. **Load and preprocess the data** (text and labels).\n",
    "2. **Split the data** into training and testing sets.\n",
    "3. **Vectorize the text data** (convert news content to numerical features).\n",
    "4. **Train a classifier** using the vectorized features.\n",
    "5. **Evaluate the model** on test data.\n",
    "\n",
    "Let's go through each of these steps in Python, assuming you have a DataFrame `df` with two columns: `'label'` (the type of news) and `'content'` (the text of the news article).\n",
    "\n",
    "### Step-by-Step Code:\n",
    "\n",
    "1. **Load and preprocess the data:**\n",
    "\n",
    "   We'll clean and tokenize the news content, and ensure the labels are encoded as categories.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load your dataframe\n",
    "df = pd.read_csv('your_file.csv')  # Replace with your actual file path\n",
    "\n",
    "# Example of data structure:\n",
    "# df = pd.DataFrame({'label': ['Sports', 'Politics', 'Technology', ...],\n",
    "#                    'content': ['Content of news article 1', 'Content of news article 2', ...]})\n",
    "\n",
    "# Encode the labels into numeric format\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# View the first few rows to check the data\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "2. **Split the data into training and test sets:**\n",
    "\n",
    "We will split the data into 80% training and 20% testing.\n",
    "\n",
    "```python\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['label_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "# View the shapes of the splits to confirm\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "```\n",
    "\n",
    "3. **Vectorize the text data:**\n",
    "\n",
    "We will use TF-IDF (Term Frequency-Inverse Document Frequency) to transform the text content into numerical features.\n",
    "\n",
    "```python\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit and transform the training data, then transform the test data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Check the shape of the resulting feature matrices\n",
    "print(f\"Training data shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Test data shape: {X_test_tfidf.shape}\")\n",
    "```\n",
    "\n",
    "4. **Train a classifier:**\n",
    "\n",
    "We will use the **Naive Bayes** classifier, which works well with text classification problems and TF-IDF features.\n",
    "\n",
    "```python\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "- **Label Encoding**: The `LabelEncoder` converts categorical labels (like \"Sports\", \"Politics\", etc.) into numeric values.\n",
    "- **TF-IDF Vectorization**: We use `TfidfVectorizer` to convert the text into a numerical format, where each word has a weight based on how frequently it appears in a document, adjusted for its frequency across the entire dataset.\n",
    "- **Multinomial Naive Bayes**: This classifier is well-suited for text classification, especially when using TF-IDF features. It assumes that the presence of each word is independent, which works well with the \"bag of words\" model.\n",
    "- **Model Evaluation**: We evaluate the model using **accuracy**, **precision**, **recall**, and **F1-score** from the `classification_report`.\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "You might see output like this:\n",
    "\n",
    "```\n",
    "Accuracy: 0.85\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       Politics       0.80      0.90      0.85       100\n",
    "        Sports       0.90      0.80      0.85       100\n",
    "   Technology       0.85      0.85      0.85       100\n",
    "\n",
    "    accuracy                           0.85       300\n",
    "   macro avg       0.85      0.85      0.85       300\n",
    "weighted avg       0.85      0.85      0.85       300\n",
    "```\n",
    "\n",
    "### 5. **Hyperparameter Tuning (Optional):**\n",
    "\n",
    "If the model’s performance isn’t satisfactory, you could:\n",
    "- Experiment with different vectorization methods (e.g., using **Word2Vec** or **BERT embeddings**).\n",
    "- Tune the hyperparameters of the Naive Bayes model or try other models (e.g., **Logistic Regression**, **SVM**, or **Random Forests**).\n",
    "\n",
    "For more advanced techniques, you can use **deep learning** models like **LSTM**, **CNN**, or **BERT**, which often provide better performance but require more computational resources.\n",
    "\n",
    "Let me know if you need further details or help with any other part of the process!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
